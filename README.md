# Awesome Inverse Graphics 
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

This is a curated list of resources and papers related to inverse graphics.  

This list will most certainly miss things, so please feel free to add a pull request or contact me directly at katiemc@mit.edu. 

Inverse graphics is a super exciting field, and hope this awesome list gets you as excited about some of these research directions as I am! 

# What is inverse graphics? 

According to Yildrim et al. in their [2015 Cog Sci paper](http://www.mit.edu/~ilkery/papers/yildirimetal_cogsci15.pdf) 

> The analysis-by-synthesis or “vision as inverse graphics” approach presents one way to think about how vision can be so rich in its content. The perceptual system models the generative processes by which natural scenes are constructed, as well as the process by which images are formed from scenes; this is a mechanism for the hypothetical “synthesis” of natural images, in the style of computer graphics. Perception (or “analysis”) is then the search for or inference to the best explanation of an observed image in terms of this synthesis model: What would have been the most likely underlying scene that could have produced this image?

# Papers  

[The Helmholtz Machine](https://www.cs.toronto.edu/~hinton/absps/helmholtz.pdf) (Dayan et al., 1995) 

[Generative models for discovering sparse distributed representations](https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.1997.0101) (Hinton & Ghahramani, 1997) 

[Instantiating Deformable Models with a Neural Net](https://papers.nips.cc/paper/1994/file/fba9d88164f3e2d9109ee770223212a0-Paper.pdf) (Williams, Revow, & Hinton, 1997)

[Object Perception as Bayesian Inference](https://escholarship.org/content/qt9q6553kr/qt9q6553kr.pdf) (Kersten, Mamassian, & Yuille, 2004)

[Vision as Bayesian Inference: Analysis by Synthesis?](https://escholarship.org/content/qt8cs5815x/qt8cs5815x.pdf?t=lnqqoj) (Yuille & Kersten, 2006) 

[Analysis-by-Synthesis by Learning to Invert Generative Black Boxes](http://www.cs.toronto.edu/~fritz/absps/vinodicann.pdf) (Nair, Susskind, & Hinton, 2008) 

[Analysis by Snythesis: A (Re-)Emerging Program of Research for Language and Vision (See Section 7)](http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/BeverPoeppel2010_AnalysisBySynthesis.pdf) (Bever & Poeppel, 2010) 

[Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs](https://proceedings.neurips.cc/paper/2013/file/fa14d4fe2f19414de3ebd9f63d5c0169-Paper.pdf) (Mansinghka et al., 2013)  

[Whatever next? Predictive brains, situated agets, and the future of cognitive science](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/whatever-next-predictive-brains-situated-agents-and-the-future-of-cognitive-science/33542C736E17E3D1D44E8D03BE5F4CD9) (Clark, 2013)

[The Informed Sampler: A Discriminative Approach to Bayesian Inference in Generative Computer Vision Models](https://arxiv.org/pdf/1402.0859.pdf) (Jampani et al., 2014) 

[Inverse Graphics with Probabilistc CAD Models](https://arxiv.org/pdf/1407.1339.pdf) (Kulkarni et al., 2014) 

[Efficient analysis-by-snythesis in vision: A computational framework, behavioral tests, and comparison with neural representations](http://www.mit.edu/~ilkery/papers/yildirimetal_cogsci15.pdf) (Yildirim et al., 2015) 

[Picture: A Probabilistic Programming Language for Scene Perception](https://mrkulk.github.io/www_cvpr15/1999.pdf) (Kulkarni et al., 2015) 

[Deep Convolutional Inverse Graphics Network](http://papers.neurips.cc/paper/5851-deep-convolutional-inverse-graphics-network.pdf) (Kulkarni et al., 2015)

[Galileo: Perceiving physical object properties by integrating a physics engine with deep learning](http://www.mit.edu/~ilkery/papers/phys_nips.pdf) (Wu et al., 2015)

[Perceiving Fully Occluded Objects via Physical Simulation](http://www.mit.edu/~ilkery/papers/perceiving-fully-occluded.pdf) (Yildirim, Siegel, & Tenenbaum, 2016)

[Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/pdf/1603.08575.pdf) (Eslami et al., 2016)

[Single Image 3D Interpreter Network](https://arxiv.org/pdf/1604.08685.pdf) (Wu et al., 2016) 

[3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction](https://arxiv.org/pdf/1604.00449.pdf) (Choy et al., 2016)

[Overcoming Occlusion with Inverse Graphics](https://link.springer.com/chapter/10.1007/978-3-319-49409-8_16) (Moreno et al., 2016)

[Neural Scene De-Rendering](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8100227) (Wu, Tenenbaum, & Kohli, 2017) 

[Vision-as-Inverse-Graphics: Obtaining a Rich 3D Explanation of a Scene from a Single Image](https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w17/Romaszko_Vision-As-Inverse-Graphics_Obtaining_a_ICCV_2017_paper.pdf) (Romaszko et al., 2017)

[Adversarial Inverse Graphics Networks: Learning 2D-to-3D Lifting and Image-to-Image Translation from Unpaired Supervision](https://openaccess.thecvf.com/content_ICCV_2017/papers/Tung_Adversarial_Inverse_Graphics_ICCV_2017_paper.pdf) (Tung et al., 2017) 

[Learning to See Physics via Visual De-animation](https://jiajunwu.com/papers/vda_nips.pdf) (Wu et al., 2017) 

[3D-Aware Scene Manipulation via Inverse Graphics](https://proceedings.neurips.cc/paper/2018/file/64223ccf70bbb65a3a4aceac37e21016-Paper.pdf) (Yao et al., 2018)

[Visual Object Networks: Image Generation with Disentangled 3D Representation](https://papers.nips.cc/paper/2018/file/92cc227532d17e56e07902b254dfad10-Paper.pdf) (Zhu et al., 2018)

[Neurocomputational Modeling of Human Physical Scene Understanding](http://cncl.yale.edu/sites/default/files/pub-downloads/CCN_2018_human_galileo.pdf) (Yildirim et al., 2018)

[Learning to Infer Graphics Programs from Hand-Drawn Images](http://people.csail.mit.edu/asolar/papers/EllisRST18.pdf) (Ellis et al., 2018)

[3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.pdf) (Kundu, Li, & Rehg, 2018)

[Learning to Reconstruct Shapes from Unseen Classes](http://genre.csail.mit.edu/papers/genre_nips.pdf) (Zhang et al., 2018)

[An integrative computational architecture for object-driven cortex](http://cncl.yale.edu/sites/default/files/pub-downloads/YildirimetalCONEUR.pdf) (Yildirim et al., 2019) 

[Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations](https://arxiv.org/pdf/1906.01618.pdf) (Sitzmann, Zollhofer, & Wetzstein, 2019) 

[InverseRenderNet: Learning single image inverse rendering](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_InverseRenderNet_Learning_Single_Image_Inverse_Rendering_CVPR_2019_paper.pdf) (Yu & Smith, 2019)

[IGE-Net: Inverse Graphics Energy Networks for Human Pose Estimation and Single-View Reconstruction](https://openaccess.thecvf.com/content_CVPR_2019/papers/Jack_IGE-Net_Inverse_Graphics_Energy_Networks_for_Human_Pose_Estimation_and_CVPR_2019_paper.pdf) (Jack et al., 2019)

[Write, Execute, Assess: Program Synthesis with a REPL](https://proceedings.neurips.cc/paper/2019/file/50d2d2262762648589b1943078712aa6-Paper.pdf) (Ellis et al., 2019)

[A Neural-Symbolic Architecture for Inverse Graphics Improved by Lifelong Meta-Learning](https://arxiv.org/pdf/1905.08910.pdf) (Kissner & Mayer, 2019)

[Efficient inverse graphics in biological face professing](https://advances.sciencemag.org/content/6/10/eaax5979) (Yildirim et al., 2020) 

[3D Morphable Face Models - Past, Present and Future](https://arxiv.org/pdf/1909.01815.pdf) (Egger et al., 2020) 

[Building 3D Morphable Models from a Single Scan](https://arxiv.org/pdf/2011.12440v1.pdf) (Sutherland, Egger, & Tenenbaum, 2020) 

[Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering](https://arxiv.org/pdf/2010.09125.pdf) (Zhang et al., 2020)

[Deep Nets: What have They Ever Done for Vision?](https://link.springer.com/article/10.1007/s11263-020-01405-z) (Yuille & Liu, 2020)

[Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured 2D Data](https://arxiv.org/pdf/2002.12674.pdf) (Lunz et al., 2020)

[Physics-as-Inverse Graphics: Unsupervised Physical Parameter Estimation from Video](https://arxiv.org/pdf/1905.11169.pdf) (Jaques, Burke, & Hospedales, 2020)

[DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning](https://arxiv.org/pdf/2006.08381.pdf) (Ellis et al., 2020)

[SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images](https://arxiv.org/pdf/2010.10505.pdf) (Lin, Wang, & Lucey, 2020) 

[Cycle-Consistent Generative Rendering for 2D-3D Modality Transition](https://arxiv.org/pdf/2011.08026.pdf) (Aumentado-Armstrong et al., 2020)

# General Resources 

[What is an Inverse Problem?](https://www.youtube.com/watch?v=RBx9D2vhGyc)

[Curated List of 3D Morphable Models](https://github.com/3d-morphable-models/curated-list-of-awesome-3D-Morphable-Model-software-and-data) 

[Pattern Synthesis](https://www.springer.com/gp/book/9780387901749) (Grenander, 1976) 

[A Stochastic Grammar of Images](https://dash.harvard.edu/bitstream/handle/1/3637153/Mumford_StochaGrammImage.pdf?sequence%3D2) (Zhu & Momford, 2007)

[Vision as Inverse Graphics for Detailed Scene Understanding](http://www.cs.toronto.edu/~bonner/courses/2020s/csc2547/papers/generative/inverse-graphics/detailed-scene-understanding,-Moreno-Comellas,-thesis-2019.pdf) (Moreno, 2019)

[Machine Learning for Machine Vision as Inverse Graphics Course](http://www.cs.toronto.edu/~bonner/courses/2020s/csc2547/) (Bonner, 2020)

# Related Talks + Videos  

[Does the Brain Do Inverse Graphics?](http://www.cs.toronto.edu/~hinton/IPAM5.pdf) (Hinton, 2015) 

[Probabilistic Programming for Augmented Intelligence](https://www.youtube.com/watch?v=Rte-y6ThwAQ) (Mansinghka, 2016)

[Computational Models of Cognition](https://www.youtube.com/watch?v=VPT73em9Nuc) (Tenenbaum, 2018)

[Inverse Programming for Deeper AI](https://www.youtube.com/watch?v=5X8cg5trO5Y) (Tavares TWIML podcast interview, 2018)

[Solving Inverse Graphics Problems In-the-Wild](https://www.youtube.com/watch?v=Zmte9dlwdWs&feature=emb_logo) (Kanazawa, 2018)

[Learning to Solve Inverse Problems in Imaging](https://www.youtube.com/watch?v=ABH5KN5DTuc) (Willet, 2019)

[Reverse-engineerring Core Common Sense](https://www.youtube.com/watch?v=Bi7_6yA1LTs) (Tenenbaum, 2020)

[Compositional Models and Occlusion](https://www.youtube.com/watch?v=Ov_FHrEM71s) (Yuille, 2020)

[AI for 3D Content Creation](https://www.youtube.com/watch?v=pTTxPq8uZmg) (Fidler, 2020)

[Implicit Neural Representations](https://www.youtube.com/watch?v=Or9J-DCDGko&t=3s) (Sitzmann, 2020)

[Integrating Learning and Graphics for 3D Scene Understanding](https://www.youtube.com/watch?v=-ltAta-No7w) (Wu, 2020)

[Common Sense Reasoning through Causal Probabilistic Programming](https://www.youtube.com/watch?v=neCwSmbmmic) (Tavares, 2020)


*Inspired by [Awesome Implicit Neural Representations](https://github.com/vsitzmann/awesome-implicit-representations) and [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision). And a huge thanks to [Bernhard Egger](https://eggerbernhard.ch/) for help with the list, as well! 

