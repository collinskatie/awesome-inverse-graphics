# Awesome Inverse Graphics 
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[Under construction!]

This is a curated list of resources and papers related to inverse graphics.  

This list will most certainly miss things, so please feel free to add a pull request or contact me directly at katiemc@mit.edu. 

Inverse graphics is a super exciting field, and hope this awesome list gets you as excited about some of these research directions as I am! 

# What is inverse graphics? 

According to Yildrim et al. in their [2015 Cog Sci paper](http://www.mit.edu/~ilkery/papers/yildirimetal_cogsci15.pdf) 

> The analysis-by-synthesis or “vision as inverse graphics” approach presents one way to think about how vision can be so rich in its content. The perceptual system models the generative processes by which natural scenes are constructed, as well as the process by which images are formed from scenes; this is a mechanism for the hypothetical “synthesis” of natural images, in the style of computer graphics. Perception (or “analysis”) is then the search for or inference to the best explanation of an observed image in terms of this synthesis model: What would have been the most likely underlying scene that could have produced this image?

# Papers 

## Foundations

## Uncategorized 

[The Helmholtz Machine](https://www.cs.toronto.edu/~hinton/absps/helmholtz.pdf) (Dayan et al., 1995) 

[Object Perception as Bayesian Inference](https://escholarship.org/content/qt9q6553kr/qt9q6553kr.pdf) (Kersten, Mamassian, & Yuille, 2004)

[Vision as Bayesian Inference: Analysis by Synthesis?](https://escholarship.org/content/qt8cs5815x/qt8cs5815x.pdf?t=lnqqoj) (Yuille & Kersten, 2006) 

[Analysis-by-Synthesis by Learning to Invert Generative Black Boxes](http://www.cs.toronto.edu/~fritz/absps/vinodicann.pdf) (Nair, Susskind, & Hinton, 2008) 

[Analysis by Snythesis: A (Re-)Emerging Program of Research for Language and Vision (See Section 7)](http://www.socsci.uci.edu/~lpearl/colareadinggroup/readings/BeverPoeppel2010_AnalysisBySynthesis.pdf) (Bever & Poeppel, 2010) 

[Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs](https://proceedings.neurips.cc/paper/2013/file/fa14d4fe2f19414de3ebd9f63d5c0169-Paper.pdf) (Mansinghka et al., 2013)  

[Whatever next? Predictive brains, situated agets, and the future of cognitive science](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/whatever-next-predictive-brains-situated-agents-and-the-future-of-cognitive-science/33542C736E17E3D1D44E8D03BE5F4CD9) (Clark, 2013)

[The Informed Sampler: A Discriminative Approach to Bayesian Inference in Generative Computer Vision Models](https://arxiv.org/pdf/1402.0859.pdf) (Jampani et al., 2014) 

[Inverse Graphics with Probabilistc CAD Models](https://arxiv.org/pdf/1407.1339.pdf) (Kulkarni et al., 2014) 

[Efficient analysis-by-snythesis in vision: A computational framework, behavioral tests, and comparison with neural representations](http://www.mit.edu/~ilkery/papers/yildirimetal_cogsci15.pdf) (Yildirim et al., 2015) 

[Picture: A Probabilistic Programming Language for Scene Perception](https://mrkulk.github.io/www_cvpr15/1999.pdf) (Kulkarni et al., 2015) 

[Deep Convolutional Inverse Graphics Network](http://papers.neurips.cc/paper/5851-deep-convolutional-inverse-graphics-network.pdf) (Kulkarni et al., 2015)

[Perceiving Fully Occluded Objects via Physical Simulation](http://www.mit.edu/~ilkery/papers/perceiving-fully-occluded.pdf) (Yildirim, Siegel, & Tenenbaum, 2016)

[Attend, Infer, Repeat: Fast Scene Understanding with Generative Models](https://arxiv.org/pdf/1603.08575.pdf) (Eslami et al., 2016)

[3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction](https://arxiv.org/pdf/1604.00449.pdf) (Choy et al., 2016) (fits here?)

[Neural Scene De-Rendering](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8100227) (Wu, Tenenbaum, & Kohli, 2017) 

[Vision-as-Inverse-Graphics: Obtaining a Rich 3D Explanation of a Scene from a Single Image](https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w17/Romaszko_Vision-As-Inverse-Graphics_Obtaining_a_ICCV_2017_paper.pdf) (Romaszko et al., 2017)

[Adversarial Inverse Graphics Networks: Learning 2D-to-3D Lifting and Image-to-Image Translation from Unpaired Supervision](https://openaccess.thecvf.com/content_ICCV_2017/papers/Tung_Adversarial_Inverse_Graphics_ICCV_2017_paper.pdf) (Tung et al., 2017) 

[Learning to See Physics via Visual De-animation](https://jiajunwu.com/papers/vda_nips.pdf) (Wu et al., 2017) 

[3D-Aware Scene Manipulation via Inverse Graphics](https://proceedings.neurips.cc/paper/2018/file/64223ccf70bbb65a3a4aceac37e21016-Paper.pdf) (Yao et al., 2018)

[Visual Object Networks: Image Generation with Disentangled 3D Representation](https://papers.nips.cc/paper/2018/file/92cc227532d17e56e07902b254dfad10-Paper.pdf) (Zhu et al., 2018)

[Neurocomputational Modeling of Human Physical Scene Understanding](http://cncl.yale.edu/sites/default/files/pub-downloads/CCN_2018_human_galileo.pdf) (Yildirim et al., 2018)

[3D-RCNN: Instance-level 3D Object Reconstruction via Render-and-Compare](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.pdf) (Kundu, Li, & Rehg, 2018)

[An integrative computational architecture for object-driven cortex](http://cncl.yale.edu/sites/default/files/pub-downloads/YildirimetalCONEUR.pdf) (Yildirim et al., 2019) 

[Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations](https://arxiv.org/pdf/1906.01618.pdf) (Sitzmann, Zollhofer, & Wetzstein, 2019) 

[Efficient inverse graphics in biological face professing](https://advances.sciencemag.org/content/6/10/eaax5979) (Yildirim et al., 2020) 

[3D Morphable Face Models - Past, Present and Future](https://arxiv.org/pdf/1909.01815.pdf) (Egger et al., 2020) 

[Building 3D Morphable Models from a Single Scan](https://arxiv.org/pdf/2011.12440v1.pdf) (Sutherland, Egger, & Tenenbaum, 2020) 

[Image GANs meet Differentiable Rendering for Inverse Graphics and Interpretable 3D Neural Rendering](https://arxiv.org/pdf/2010.09125.pdf) (Zhang et al., 2020)

[Deep Nets: What have They Ever Done for Vision?](https://link.springer.com/article/10.1007/s11263-020-01405-z) (Yuille & Liu, 2020)

[Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured 2D Data](https://arxiv.org/pdf/2002.12674.pdf) (Lunz et al., 2020)

[Physics-as-Inverse Graphics: Unsupervised Physical Parameter Estimation from Video](https://arxiv.org/pdf/1905.11169.pdf) (Jaques, Burke, & Hospedales, 2020)

[SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images](https://arxiv.org/pdf/2010.10505.pdf) (Lin, Wang, & Lucey, 2020) 

# General Resources 

[Curated List of 3D Morphable Models](https://github.com/3d-morphable-models/curated-list-of-awesome-3D-Morphable-Model-software-and-data) 

[Pattern Synthesis](https://www.springer.com/gp/book/9780387901749) (Grenander, 1976) 

[A Stochastic Grammar of Images](https://dash.harvard.edu/bitstream/handle/1/3637153/Mumford_StochaGrammImage.pdf?sequence%3D2) (Zhu & Momford, 2007)


# Talks + Videos  

[Does the Brain do Inverse Graphics?](http://www.cs.toronto.edu/~hinton/IPAM5.pdf) (Hinton, 2015) 


*Inspired by [Awesome Implicit Neural Representations](https://github.com/vsitzmann/awesome-implicit-representations) and [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)

